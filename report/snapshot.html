<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>Technological Approaches to Improving Credibility Assessment on the Web</title>
  <script src="https://www.w3.org/Tools/respec/respec-w3c-common" class="remove">
  </script>
  <script class="remove">
  var respecConfig = {
    "gdocID": "1WWYQ33Y9ENcueiFnrb3hJzD2rxKCRw9ok8T3PrDLOB8",
    "noRecTrack": true,
    "edDraftURI": "https://credweb.org/report/snapshot",
    "specStatus": "ED",
    "editors": [
        {
            "name": "Sandro Hawke",
            "url": "http://hawke.org/sandro"
        }
    ],
    "github": "https://github.com/w3c/credweb",
    "shortName": "not-published-as-TR",
    "abstractHTML": "Abstract TBD",
    "sotdHTML": "\n    <div id=\"real-sotd\" style=\"margin: 1em; border: 4px solid blue; padding: 1em\">\n    <p>This is just an un-reviewed editors draft.  Please send comments.</p>\n    <p>If you're okay with Google Docs, please <b><a href=\"https://docs.google.com/document/d/1WWYQ33Y9ENcueiFnrb3hJzD2rxKCRw9ok8T3PrDLOB8\">use the live version</a></b>.</p>\n    <p>This snapshot version is made from time to time, but is no more stable or authoritative than the live version.</p>\n    </div>\n",
    "title": "Technological Approaches to Improving Credibility Assessment on the Web"
}
  </script>
</head>
<body>
  <div id="abstract">Abstract TBD</div>
  <div id="sotd">
    <div id="real-sotd" style="margin: 1em; border: 4px solid blue; padding: 1em">
    <p>This is just an un-reviewed editors draft.  Please send comments.</p>
    <p>If you're okay with Google Docs, please <b><a href="https://docs.google.com/document/d/1WWYQ33Y9ENcueiFnrb3hJzD2rxKCRw9ok8T3PrDLOB8">use the live version</a></b>.</p>
    <p>This snapshot version is made from time to time, but is no more stable or authoritative than the live version.</p>
    </div>
</div>

<section>
    <h1 id="h.hoc6clg2vmn6">Introduction</h1>
    <p>Can you tell, when you&apos;re looking at a random web page, whether you should trust it? When scanning a page of search results, do you know which matches come from legitimate sources and which are scams? When reading a news feed, can you tell which items ought to be believed and which are slanted, manipulative, or outright lies? Perhaps most importantly, what happens when you inevitably guess wrong while making some of these credibility assessments, and you unknowingly share falsehoods to your community? &#xA0;What if you are misled into making bad decisions for yourself and the people you care about?</p>
    <p></p>
    <p>The <a href="https://www.google.com/url?q=https://credweb.org&amp;sa=D&amp;ust=1535307140723000">Credible Web Community Group</a>&#xA0;formed at W3C, the organization which develops technical standards for the web, to look for technological solutions for this &#x201C;credibility assessment&#x201D; problem. It&apos;s not that we think tech can solve every problem, especially ones as deeply human and complex as this one, but it seems likely that some tech is making matters worse and that other designs could probably serve people better. For some of us, creating better approaches to credibility assessment seems like a good way to help.</p>
    <p></p>
    <p>This document is a work in progress&#xA0;and edits are welcome. &#xA0;The document collects ideas, mostly following discussion at meetings of the group. For simplicity and to keep the focus on improving the ideas, provenance/attribution information is generally omitted (that is, we don&#x2019;t attach ideas to people). In some cases such details are available in meeting minutes and in other documents.</p>
    <section>
        <h2 id="h.v8boqqhafijm">Terminology</h2>
        <p>Ecosystem Roles:</p>
        <ul><li>(Content) <b>Consumer</b>: person who is receiving and experiencing some content. &#xA0;Similar to: Audience Member, Reader, Viewer, Listener, Receiver, User</li><li>(Content) <b>Provider</b>: person or organization who provided the consumer with some content. There may be a supply chain of providers, creating and assembling content before it reaches the consumer. Often this is invisible to the consumer, who perceives (and makes credibility assessments about) a single apparent provider. &#xA0;Similar to: Producer, Creator, Author, Publisher</li><li>(Credibility) <b>Facilitator</b>: &#xA0;person or organization who is helping the consumer decide what to trust. &#xA0;Similar to: Moderator, Fact-Checker, Forum or Comments Editor.</li><li>(Web-Based Communication) <b>Platform</b>: technological system, and by extension the person or organization who maintains and controls it, which is providing the above parties with the infrastructure which enables the content to pass among them. &#xA0;Includes Content Management Systems (CMSs), Web Browsers, Search Engines, and News Feeds.</li></ul>
        <p></p>
    </section>
</section>
<section>
    <h1 id="h.rcs17hj6bu6r">Scope</h1>
    <p>Web-centric technical solutions which requires standardization</p>
    <p></p>
    <p>The web isn&apos;t everything but it&apos;s arguably the knowledge backbone of the world today. &#xA0;Everything can and usually does tie back to the web to some degree, so if the web is a reliable source of accuracy, that should help quite a bit.</p>
    <p></p>
    <p>Data interchange vocabularies are the likely main area to standardize. See below, <a href="#h.wpcxeg3cugmx">Potential New Web Standards</a></p>
    <p></p>
    <p>Browser functionality is another possibility, but the bar is much higher, and none of the current proposals require that to function, although it would certainly help with deployment.</p>
</section>
<section>
    <h1 id="h.bjkr6l1byyj4">First, Do No Harm: Hazards of Intervention</h1>
    <section>
        <h2 id="h.2cd6cv1rre9i">Censorship</h2>
        <p>The regulation of content (called &quot;censorship&quot; in some contexts) is controversial. Nearly every country in the world considers publication of certain kinds of material immoral and illegal (such as child pornography). &#xA0;At the same time, many of the same countries express the value of free speech and a free press, sometimes in very broad language. To humans, the difference may be laughably clear, but in general a computer system designed to allow one kind of content to be blocked can also be used to block all the other kinds.</p>
        <p></p>
        <p></p>
        <p>Additionally, the people and computing systems involved in a potentially-problematic communication may be spread out over time and place, each subject to different cultural views and applicable legal authorities.</p>
        <p></p>
        <p>[ explain the Web currently handles this by not blocking anything but making it hard to publish anonymously, and folks who want to publish anonymously have to trust someone else to protect their identity, eg a social media platform. &#xA0; And we think this architecture makes sense to continue.]</p>
        <p></p>
        <p>Perhaps the best path forward is to aim for systems which allow users to publish and view any available content they chose, but also to enable those individuals to be held accountable if they break the laws which apply to them. Legitimate needs for anonymity could be handled within such a scheme by using trusted proxies, such as journalists.</p>
    </section>
    <section>
        <h2 id="h.qayku97gyi0m">Centralization</h2>
        <p>Some proposals require or facilitate centralization, such as the idea of establishing and enforcing uniform standards for journalism. &#xA0;These approaches have some appeal and might be effective, but centralization is antithetical to Web Architecture and would likely introduce problems with scaling, censorship, and political bias. We have been considering centralized approaches out-of-scope, and aim for designs which give the end-user final control over their computing platform.</p>
    </section>
    <section>
        <h2 id="h.1g77pcw323di">Tribalism, Echo Chambers, Filter Bubbles</h2>
        <p>Some proposals are likely to increase the degree to which consumers see only the content they want to see or their community wants them to see, regardless of its accuracy.</p>
        <p></p>
        <p>One theory on addressing this is to make clear to users when they are inside their bubble (their personal walled garden) and to allow them to easily step outside of it, whenever they want. The theory is that people won&#x2019;t always choose to be sheltered, but will instead sometimes be looking for adventure, or something, &#x201C;outside the wall&#x201D;. &#xA0; </p>
        <p></p>
        <p>It has also been suggested that prediction markets incentivize accurate broad knowledge, leading people outside their bubbles, and that commerce/trade in general motivates people to connect between &#x201C;tribes&#x201D; and help people get along regardless of &#x201C;tribe&#x201D;.</p>
    </section>
    <section>
        <h2 id="h.erwe81uzigvy">Other Unintended consequences</h2>
        <p>eg Facebook result that warning labels on false news increased increased engagement, so test thoroughly before deploying at scale. &#xA0;That&#x2019;s very hard to do in decentralized/open systems.</p>
    </section>
    <section>
        <h2 id="h.vcnrv18hbkbk">Review Board</h2>
        <p>People are notoriously bad at seeing the downsides of work they support. As such, an adversarial approval process -- where work must be reviewed by disinterested and potentially hostile parties before it can proceed -- is often useful to vet work that needs to be of high quality.</p>
        <p></p>
        <p>It may be wise to set up a Review Board to oversee potential interventions around credibility. Models for this include <a href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Institutional_review_board&amp;sa=D&amp;ust=1535307140730000">IRBs</a>, approval processes for medical treatments, and <a href="https://www.google.com/url?q=https://www.w3.org/Guide/process/charter.html%23horizontal-review&amp;sa=D&amp;ust=1535307140731000">W3C&apos;s Horizontal Review process</a>.</p>
        <p></p>
        <p>Such a review board might be useful for vendor-specific interventions as well as standards-based ones, and could bring considerable credibility to the process if staffed with people respected by diverse stakeholders.</p>
    </section>
</section>
<section>
    <h1 id="h.ij0k32jlsndm">Granularity: Which Entities Are You Assessing for Credibility?</h1>
    <p>People necessarily make credibility assessments about content items and about the people who provided the content. It seems likely they make these assessments across a wide range of granularities.</p>
    <section>
        <h2 id="h.5uftu3raaxuh">People and Organizations (Content Providers)</h2>
        <p>For example, Harvard University would be large-granularity source, comprising many people over several centuries, but still having some degree of aggregate credibility. &#xA0;In contrast, in considering the credibility of Harvard Professor Jonathan Zittrain, one would be working at a smaller granularity. &#xA0;An even smaller granularity might be Professor Zittrain during a given conversation or on a given topic. &#xA0;For example, he might be much more credible when speaking about issues concerning the Internet and Society than about 12th century French poetry.</p>
        <p></p>
    </section>
    <section>
        <h2 id="h.st1avm3jie2h">Content and Claims</h2>
        <p>Reasoning about the credibility of content similarly requires working with a range of granularities. For example, we might consider the credibility of a snapshot of Wikipedia, or of a particular Wikipedia page, or the text of a paragraph, or a specific claim.</p>
    </section>
    <section>
        <h2 id="h.anvuxde13i6n">Complications due to the Web</h2>
        <p>In general, working with metadata about web content, it often works to design for web pages, then extend the granularity up to origins (loosely, domain names) and down to fragments (loosely, portions of a page or portions of media shown on the page). &#xA0;Note that the Web Annotation framework <a href="https://www.google.com/url?q=https://www.w3.org/TR/selectors-states/%23json-examples-converted-to-fragment-identifiers&amp;sa=D&amp;ust=1535307140733000">specifies a way</a>&#xA0;to make essentially any portion of any version of a page be its own addressable fragment, although that it not yet widely implemented.</p>
        <p></p>
        <p>Sites which aggregate content from other providers, including social media sites, will need special consideration, as will sites which analyze or review other content, sometimes including false content as an example or evidence.</p>
        <p></p>
        <p>Credibility ratings for a web page may at first seem to be just about whether the <i>content</i>&#xA0;is trustworthy, but in practice websites can change their content or even secretly show different content to different observers, so the trustworthiness of the site maintainer is a factor as well. For assessments to securely apply to just the intended content of a page and not also include its provider, some mechanism is needed to securely indicate the exact content being considered. &#xA0;</p>
    </section>
</section>
<section>
    <h1 id="h.4nvodw32hqjj">Assessment Strategies: How Can You Tell What To Believe?</h1>
    <p>[Move this section to the Intro, maybe under Terminology?]</p>
    <p></p>
    <p>Techniques for assessing credibility can be grouped roughly into the following four types of strategies. &#xA0;These grouping were originally based on particular projects which focused on only one of the areas. &#xA0;Each of these strategies could be applied with a wide range of computer assistance, and some technologies will likely combine elements of several strategies.</p>
    <p></p>
    <ol start="1"><li><b>Inspection.</b>&#xA0;Look closely at the content (and the page where it appears) for the presence of features which are statistically associated with low or high credibility. This may be the primary strategy consumers use unconsciously while reading. The hope is that assessment accuracy can be significantly improved with computer assistance and suitable grounding research.</li><li><b>Corroboration.</b>&#xA0;Identify salient claims made (or implied, or relied upon) in the content and check other sources which offer an assessment of the claim (eg fact-checks), or related claims, or evidence helping the consumer accurately assess the claim. &#xA0;</li><li><b>Reputation.</b>&#xA0;Assess the credibility of a content provider by gathering statements about them from other high-credibility providers. &#xA0;This can be done recursively, forming a reputation network from a few known and trusted &#x201C;root&#x201D; providers to help assess many unknown and suspect ones. &#xA0;</li><li><b>Transparency.</b>&#xA0;Consider what the provider says about themselves and their content. &#xA0;For instance, content may be labeled as opinion or even satire, and providers may label themselves as partisan or having processes and controls the consumer views as untrustworthy. &#xA0;By itself, this data is easy to fake, but coupled with corroboration, reputation, and off-line social and legal incentives, it may be quite effective.</li></ol>
</section>
<section>
    <h1 id="h.7vnom1uxezjj">User Experience (UX)</h1>
    <p>Users might experience credibility assessment tools in a variety of ways, including:</p>
    <p></p>
    <ul><li>as a browser extension</li><li>built into a browser</li><li>as a web app</li><li>as a native app</li><li>as part of a newsfeed</li><li>as part of a web search engine</li><li>as part of a website&apos;s search function</li></ul>
    <p></p>
    <section>
        <h2 id="h.2322azaw5nmq">Consciousness and Initiative</h2>
        <p>We can divide the UX into three main modes of interaction based on the user&#x2019;s state of mind around credibility assessment.</p>
        <section>
            <h3 id="h.qas3hox31x2c">Initiated by User</h3>
            <p></p>
            <p>These only help when the user consciously wonders whether to trust the content.</p>
            <p></p>
            <p>Most of these are perhaps best done at the claim level, where the user indicates a specific questionable claim in the content, rather than a whole page or site.</p>
            <p></p>
            <ul><li>request reputation/background information about site</li><li>request immediate check (ie by software)</li><li>request a check soon (ie by other people)</li><li>offer to pay for quality fact-check</li><li>add annotation for others to be skeptical</li><li>add annotation linking to fact checks</li><li>add annotation linking to relevant evidence</li></ul>
        </section>
        <section>
            <h3 id="h.ktv5k7x4ynxc">Alerting User</h3>
            <p>These risk triggering a backfire effect, as users may cling to false beliefs more when corrected. &#xA0;Proper presentation, such as attributing the correction to a user-selected trusted source might help with this.</p>
            <p></p>
            <ul><li>offer fact checks in a sidebar</li><li>add fact checks in flow of page</li><li>add interstitial warning page, when content is assessed as very-low-credibility</li><li>block out low-credibility content on page display with a warning, awaiting confirmation. Similar to content-warnings and spoiler-warnings on some sites.</li></ul>
        </section>
        <section>
            <h3 id="h.10czfmxsvuq3">Passively Guiding the User</h3>
            <p></p>
            <p>Some of these could impinge on the user&apos;s autonomy or confuse the user.</p>
            <p></p>
            <ul><li>Block the content, acting as if it does not exist</li><li>Demote, so it appear much later in news feed or search results </li><li>Label with credibility level</li><li>Style content differently based on credibility level</li><li>Suggest related content which is likely to be corrective</li></ul>
            <p></p>
        </section>
    </section>
    <section>
        <h2 id="h.jp512yw2mt2f">Identity and Privacy</h2>
        <p>Many of these actions have strong privacy and data ownership considerations. If these were built into the browser, where would the data end up shared? &#xA0;If these are built into anything else, how does that not centralize the feature and create a new silo?</p>
    </section>
</section>
<section>
    <h1 id="h.a1znaka91j8o">Threat Models: How Might Attacks Impact You?</h1>
    <p>(This section needs some actual threat modeling, still)</p>
    <section>
        <h2 id="h.c73erst6eh1i">Attacker Motivations</h2>
        <ol start="1"><li>Ethical business, wants long term business relationship. &#xA0;This is legitimate advertising.</li><li>Unethical or illegal business, wants money with little regard for consequences</li><li>Non-ideological political operative, wants legitimately-obtained authority (&#x201C;tribal&#x201D; power) </li><li>Ideological political operative (activist), wants to change society in a specific way</li><li>Prankster, wants amusement or personal attention, </li><li>Harmful person (troll, stalker, hater, ...), wants personal sense of power, entertainment at the expense of others, personal vengeance, etc</li><li>Mentally unstable person, unknown wants, presents erratic, irrational behavior.</li></ol>
    </section>
    <section>
        <h2 id="h.srnu4vlrt8gx">Attacker Resource Levels</h2>
        <ol start="1"><li>Unskilled individual with a brief impulse</li><li>&#x2026; &lt;ranging to&gt; ...</li><li>Nation with cyber warfare capabilities engaged in authorized action</li></ol>
        <p></p>
    </section>
    <section>
        <h2 id="h.yj8yphmtgd7n">Intended Impact</h2>
        <ul><li>Voting</li><li>Viewing ads</li><li>Social media behavior</li></ul>
        <ul><li>Engage</li><li>Reply</li><li>Share</li><li>Like</li><li>Report</li></ul>
        <ul><li>Offline social behavior: spreading rumours, attending rallies</li><li>Consumer choices, what to buy</li><li>Donation choices, where to give money</li><li>Lifestyle</li><li>Shape the narrative, influencing how future stories are interpreted</li></ul>
        <p></p>
    </section>
    <section>
        <h2 id="h.1lqv13f2ek75">Mental Attack Vectors</h2>
        <ul><li>Emotional Hijacking - Humans are great at making rational decisions, as long as they don&#x2019;t care about the outcome</li><li>Setting the Initial Frame</li><li>Tribalism</li><li>Fear, Uncertainty, and Doubt</li><li>Misleading with Statistics - eg Humans are terrible at assessing the odds of unlikely events</li><li>Judging a book by its cover - a good looking website can be extremely convincing</li><li>Confusingly similar account names or domain names or brands</li></ul>
    </section>
    <section>
        <h2 id="h.5logre8458bk">Technological Attack Vectors</h2>
        <ul><li>Bots</li><li>Web Tracking</li><li>IoT hijacking</li></ul>
    </section>
</section>
<section>
    <h1 id="h.3ggo9gzfv1jw">Stakeholders: Who Might Care Enough To Do Something?</h1>
    <p>See <a href="https://www.google.com/url?q=https://docs.google.com/spreadsheets/d/1vWE3iOn6yxUsRJyS_mks83m0Gwv_7cK0WtVt-SNsYzY/edit%23gid%3D0&amp;sa=D&amp;ust=1535307140751000">landscape spreadsheet</a>&#xA0;for now</p>
    <section>
        <h2 id="h.fxqpkimxqram">Related Projects</h2>
        <p>Maybe indicate active liaisons, and describe relationship, and which strategies they connect to.</p>
    </section>
    <section>
        <h2 id="h.fohxp55tfyfn">Industries</h2>
    </section>
    <section>
        <h2 id="h.u5wbfe84bgm3">Organizations</h2>
        <p></p>
    </section>
</section>
<section>
    <h1 id="h.rmx3ty7g6ge9">Deployment Strategies</h1>
    <p>[Maybe flesh these out in terms of the specific technical solutions ]</p>
    <p></p>
    <ul><li>Via providers to their community; eg news site embeds credibility assessment tool in their web pages</li><li>Via cms plugin providers</li><li>Via schools, to their community</li><li>Via enterprise, to their employees, including via standard machine configs</li><li>Via membership organization which can convince its members to install app/plugin</li><li>Via social graph, using &#x201C;help protect your community/friends&#x201D; pitch</li><li>Implement in browser</li><li>Implement in platform</li></ul>
    <p></p>
    <p>[ Talk about funding. &#xA0;Maybe there should be grant and investment and bootcamp programs around these interventions. ]</p>
</section>
<section>
    <h1 id="h.2weumcgoexza">Promising Technical Solutions: What Can Be Done?</h1>
    <p>These are grouped by <a href="#h.4nvodw32hqjj">Assessment Strategy</a>&#xA0;for clarity.</p>
    <p></p>
    <p>[Maybe rephrase in terms of a particular software products that could be built, and what the desired impact would be. &#xA0;Hopefully fill in, in time, with products that do that. &#xA0;Maybe useful for a hackathon, incubator, social investment fund.]</p>
    <p></p>
    <section>
        <h2 id="h.tri3dd872c3p">Inspection</h2>
        <ol start="1"><li>Tools can help humans inspect content for known and potential credibility signals</li><li>That data can then be shared, subject to privacy considerations, for multiple purposes.</li><li>Data from multiple annotators can be compared against each other and against standardized test data to assess how well the measurement process is working, in terms of both precision and accuracy, and to potentially detect problematic annotators.</li><li>Annotations on test content can be used to validate the connection between signals and the truth. Note the connection might be a positive correlation (signal indicates high credibility), negative correlation (signal indicates low credibility), or there might be a multifactor connection found by machine learning techniques.</li><li>This data can be used directly to signal credibility levels to other consumers</li><li>It can also be used to train machine models which can then potentially also do the step 1 job</li></ol>
        <p></p>
        <p>People in step 1 might be motivated by:</p>
        <ul><li>Being paid by platforms or aggregated consumers</li><li>Volunteering in the name of promoting truth/accuracy for their community or the world</li><li>Helping themselves determine whether to trust the content</li></ul>
        <p></p>
        <p>Machines programmed/trained to do step 1 will probably be faster and cheaper, and might in time become more accurate and trustworthy. They will likely also have unpredictable failure modes (bugs, unexpected training artifacts) which might pose a security vulnerability to be considered.</p>
        <p></p>
        <p>Gameability: signals which are financially prohibitive to fake</p>
        <p>&#xA0; - attacker can&apos;t use best tools (reduce income)</p>
        <p>&#xA0; - attacker needs expensive people/tools to create (increase cost)</p>
    </section>
    <section>
        <h2 id="h.mtw2w6x2rcjp">Corroboration</h2>
        <p>See issues and discussion at <a href="https://www.google.com/url?q=https://github.com/w3c/cred-claims&amp;sa=D&amp;ust=1535307140759000">https://github.com/w3c/cred-claims</a></p>
        <p></p>
        <ol start="1"><li>Allow professional fact-checks to be published in machine readable form so they can more easily be matched, used in automated assessments, and shown to users when appropriate. (Already being done using claimreview)</li><li>Allow claim-extraction processes to publish their output for broad consumption. This would be a feed of claims found in the media and judged to be of relatively high value for checking.</li><li>Allow users to express their desire for specific claims in some content to be checked. Might include offer to pay for results.</li><li>Allow relationships between claims to be expressed, such as rephrasings to be more precise and context-free vs more terse and context-sensitive, more in agreement vs disagreement with the claim itself, making a broader vs narrower claim, between natural languages, and opposites.</li><li>Allow structure of a fact-check to be exposed as machine-readable, showing argumentation and secure links to the evidence</li><li>Allow end-users to express what they feel or know relevant to a claim&#x2019;s accuracy, in a way that might be reasonable aggregated toward accurate credibility assessment. It&apos;s important this not be simply popularity polling; important ideas, when they start, are usually believed by exactly one person.</li><li>Make it easy to view reviews of related claims from many sources at once, including some data about the sources, such as assessed bias</li></ol>
        <p></p>
        <p>Some of these rely on emerging technologies:</p>
        <p></p>
        <ul><li>Claim extraction: given some natural language text, recognize fragments that are likely to be checkable claims</li><li>Claim matching: given some claim text, find other claims which are likely to be highly relevant</li><li>Claim interpretation: given some natural language claim text, automatically perform relevant databases searches and calculations to check it</li></ul>
        <p></p>
    </section>
    <section>
        <h2 id="h.41t1lbapkm9n">Reputation</h2>
        <p>@@cleanup</p>
        <p></p>
        <p>-- white lists</p>
        <p>-- auditing</p>
        <p>-- certification</p>
        <p>-- what do you say about others</p>
        <p>-- what do others say about some content</p>
        <p></p>
        <p></p>
        <p>&#xA0; - Allow individuals and organizations to express their view on</p>
        <p>&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;credibility of others</p>
        <p></p>
        <p>&#xA0; - Agree on certain levels, eg &quot;good faith participant&quot;</p>
        <p></p>
        <p>&#xA0; - Have certain trusted agencies which establish reliable identity of</p>
        <p>&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;publishers</p>
        <p></p>
        <p>&#xA0; - Have certain trusted agencies vet self-disclosure statements</p>
        <p></p>
        <p></p>
        <p>&#xA0; * Software working on your behalf can try to ascertain the reputation</p>
        <p>&#xA0; of each website you visit based on what has been said about them by</p>
        <p>&#xA0; entities you select, and by intermediate parties in a social graph. </p>
        <p></p>
        <p>&#xA0;* Software can aggregate what others have said about a particular web</p>
        <p>&#xA0; page that bears on its credibility </p>
        <p></p>
    </section>
    <section>
        <h2 id="h.uczdbpambvtx">Transparency</h2>
        <p></p>
        <p>@@cleanup</p>
        <p></p>
        <p>-- what can one say about oneself to be more visibly trustworthy</p>
        <p></p>
        <p>&#xA0; - Label article types (eg opinion)</p>
        <p></p>
        <p>&#xA0; - Label account types (eg parody)</p>
        <p></p>
        <p>&#xA0;</p>
        <p>&#xA0;* Software can highlight sites which offer transparency disclosures</p>
        <p></p>
        <p>&#xA0;* Software can highlight aspects of the transparency disclosures which</p>
        <p>&#xA0; might be especially relevant to you, based on your values or stated</p>
        <p>&#xA0; trust concerns </p>
        <p></p>
        <p>&#xA0;* Software can particularly highlight supportive and refutive claims</p>
        <p>&#xA0; from known 3rd parties about self-descriptive claims. (Combines with reputation)</p>
    </section>
</section>
<section>
    <h1 id="h.wpcxeg3cugmx">Potential New Web Standards</h1>
    <p>Each of the below potential standards is intended to allow systems to interoperate by sharing data with common syntax and semantics. &#xA0;The expectation is that data sharing will be done in a manner compatible with of <a href="https://www.google.com/url?q=https://schema.org/&amp;sa=D&amp;ust=1535307140769000">schema.org</a>&#xA0;using W3C standard data technologies like <a href="https://www.google.com/url?q=https://www.w3.org/TR/json-ld/&amp;sa=D&amp;ust=1535307140769000">JSON-LD</a>. These build on the underlying general graph model of <a href="https://www.google.com/url?q=https://www.w3.org/TR/rdf11-concepts/&amp;sa=D&amp;ust=1535307140769000">RDF</a>&#xA0;and support related technologies like the <a href="https://www.google.com/url?q=https://www.w3.org/TR/sparql11-overview/&amp;sa=D&amp;ust=1535307140769000">SPARQL</a>&#xA0;query language, but can usually be used as ordinary JSON embedded in web pages. In each case, the purpose is to allow various independent systems to provide data feeds which can be easily and unambiguously understood by other systems across the Web.</p>
    <section>
        <h2 id="h.gy5qpmoxmiff">Inspection</h2>
        <p>Standard for expressing features of web pages and their content which bear on credibility and which are relatively expensive to fake. When humans are recognizing the features, this would allow their work to be shared. &#xA0;When software is recognizing the features, it would allow a more standard API between modules. &#xA0;Standardization would also allow people to be trained to work with these features in creating content and in mentally assessing credibility.</p>
    </section>
    <section>
        <h2 id="h.bb2miqm37qkl">Corroboration</h2>
        <p>Standard for:</p>
        <ul><li>Fact-checkers to publish their work in a way which can be easily aggregated (largely already done with ClaimReviw) </li><li>Representing the argumentation structure of a fact-check, making it easier to re-check</li><li>People and machines to indicate which claims they think should be fact-checked</li><li>Expressing sightings of a claim and connecting them with existing fact checks </li><li>Expressing retractions (self-claim-check)</li></ul>
    </section>
    <section>
        <h2 id="h.snmhmyeu59cm">Reputation</h2>
        <p>Standards&#xA0;for reputation of providers:</p>
        <ul><li>Expressing a list of approved members of an organization (eg <a href="https://www.google.com/url?q=https://github.com/IFCN/verified-signatories/blob/master/list&amp;sa=D&amp;ust=1535307140772000">IFCN</a>, <a href="https://www.google.com/url?q=https://www.w3.org/Consortium/Member/List&amp;sa=D&amp;ust=1535307140772000">W3C</a>, or AP)</li><li>Expressing a list of employees, students, or other vetted individuals</li><li>Expressing that an organization or individual or some content has been vetted and approved for some particular quality/credential/certificate.</li><li>Expressing the identity of the people behind a site </li><li>Expressing the partisan leanings of a provider, or other bias</li><li>Expressing the belief that a provider acts in good faith in the service of accurate content, or fails to do so</li><li>&#x2026; other reputational information</li></ul>
        <p></p>
        <p>Standards for reputation of content:</p>
        <ul><li>Expressing engagement metrics, allowing 3rd parties to see indicators of virality </li></ul>
    </section>
    <section>
        <h2 id="h.1zfuop38heni">Transparency</h2>
        <p>Some work already done with the <a href="https://www.google.com/url?q=https://thetrustproject.org/&amp;sa=D&amp;ust=1535307140774000">Trust Project</a>&#xA0;and schema.org. &#xA0;Unclear what else might be valuable.</p>
    </section>
    <section>
        <h2 id="h.sckyfsyg61hc">Other</h2>
        <p>Define a way for one provider to embed content from another without endorsement. This would be for credibility a bit like <a href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Nofollow&amp;sa=D&amp;ust=1535307140775000">nofollow</a>&#xA0;was for SEO. &#xA0;An iframe would be the natural web way to do this, but 3rd party content on social media doesn&#x2019;t currently work that way. There is also the question whether the visited site can be entirely blameless for harmful 3rd party content; perhaps it can embed it with indicators about what editorial/review process it followed, if any.</p>
    </section>
</section>
<section>
    <h1 id="h.44v9zb7xawl2">Reading List</h1>
    <section>
        <h2 id="h.9h9dwq5xozdh">Getting Started</h2>
        <p><a href="https://www.google.com/url?q=https://docs.google.com/document/d/1OPghC4ra6QLhaHhW8QvPJRMKGEXT7KaZtG_7s5-UQrw/edit%23heading%3Dh.l3iqngk38nap&amp;sa=D&amp;ust=1535307140776000">Design Solutions for Fake News</a>&#xA0;is a sprawling (200+ page) crowd-sourced Google-Doc, initiated by Eli Pariser after the 2016 election of Donald Trump. &#xA0;It approaches many of the same ideas as this document, from some different angles.</p>
        <p></p>
        <p><a href="https://www.google.com/url?q=https://crestresearch.ac.uk/comment/pereira-partisan-brain-fake-news/&amp;sa=D&amp;ust=1535307140776000">The Partisan Brain: Why People Are Attracted To Fake News And What To Do About It</a></p>
    </section>
    <section>
        <h2 id="h.d461wikn28pg">Books</h2>
    </section>
    <section>
        <h2 id="h.8zd5evin4lng">Peer-Review Journals and Conferences</h2>
    </section>
    <section>
        <h2 id="h.j5cokdvcfbc">Ongoing: Newsletters, Blogs, Podcasts, &#x2026;</h2>
        <ul><li>The <a href="https://www.google.com/url?q=https://www.poynter.org/channels/fact-checking&amp;sa=D&amp;ust=1535307140777000">&#xA0;International Fact-Checking Network @ Poynter (IFNC)</a>&#xA0;has a weekly <a href="https://www.google.com/url?q=http://go.pardot.com/l/273262/2018-05-29/5jcnr&amp;sa=D&amp;ust=1535307140778000">newsletter</a></li></ul>
        <ul><li>The <a href="https://www.google.com/url?q=http://www.niemanlab.org/&amp;sa=D&amp;ust=1535307140778000">Nieman Journalism Lab</a>&#xA0;at Harvard has a weekly <a href="https://www.google.com/url?q=http://www.niemanlab.org/subscribe/&amp;sa=D&amp;ust=1535307140779000">newsletter</a>.</li></ul>
        <p></p>
    </section>
</section>
<section>
    <h1 id="h.jg0o5v2af3r5">Acknowledgements</h1>
    <section>
        <h2 id="h.ceqaaaksazvr">Regular Group Participants</h2>
    </section>
    <section>
        <h2 id="h.12uyfco0h36d">Review Comments</h2>
        <p>We are grateful for review comments from these individuals. &#xA0;These people <b>do not necessarily endorse this document.</b>&#xA0; Please add your name/affiliation here if submitting review comments.</p>
        <p></p>
        <ul><li>Amy Guy</li><li>George Linzer</li></ul>
        <p></p>
    </section>
</section>
</body></html>
